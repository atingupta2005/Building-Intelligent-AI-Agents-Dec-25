{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9OO2FoA1YTL"
   },
   "source": [
    "# Day 2: LangChain vs. LangGraph - The Self-Correcting AI Researcher\n",
    "\n",
    "**Objective:** To understand the practical differences between a standard `AgentExecutor` and `LangGraph` for building complex, stateful AI agents.\n",
    "\n",
    "In this notebook, we will attempt to build an agent with a crucial capability: **self-correction**. The agent's task is to research a topic, but with a twist. It must:\n",
    "1. Perform an initial web search.\n",
    "2. **Analyze** its own search results to see if they are good enough.\n",
    "3. If the results are poor, it must **rewrite** its search query and try again.\n",
    "4. Only when it has sufficient information should it provide a final answer.\n",
    "\n",
    "This cyclical, self-evaluating behavior is a hallmark of more advanced, reliable agents. We will see how a standard agent struggles with this task and how LangGraph is explicitly designed to solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvy1rvSp1YTM"
   },
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, let's install the necessary libraries. We will use `ddgs` for DuckDuckGo search as the older package is deprecated. Then we'll import our modules and set up the environment. Make sure you have a `.env` file in the same directory with your `OPENAI_API_KEY`, or set it up as a secret in your Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Kivq7Lk27Tg",
    "outputId": "2c78a73f-00e1-4da2-c863-2ef4c50001ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: requests 2.32.5\n",
      "Uninstalling requests-2.32.5:\n",
      "  Successfully uninstalled requests-2.32.5\n",
      "Found existing installation: tenacity 8.5.0\n",
      "Uninstalling tenacity-8.5.0:\n",
      "  Successfully uninstalled tenacity-8.5.0\n",
      "Found existing installation: packaging 23.2\n",
      "Uninstalling packaging-23.2:\n",
      "  Successfully uninstalled packaging-23.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping langchain as it is not installed.\n",
      "WARNING: Skipping langchain-core as it is not installed.\n",
      "WARNING: Skipping langchain-community as it is not installed.\n",
      "WARNING: Skipping langchain-openai as it is not installed.\n",
      "WARNING: Skipping langgraph as it is not installed.\n",
      "WARNING: Skipping openai as it is not installed.\n",
      "WARNING: Skipping tiktoken as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "ip uninstall -y langchain langchain-core langchain-community langchain-openai langgraph openai  tiktoken requests  tenacity  packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seHwmFQa3ZRH",
    "outputId": "83606abd-8e64-4abf-beb4-494d77e9cfea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: No matching packages\n"
     ]
    }
   ],
   "source": [
    "pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WWMXYC6E1YTM",
    "outputId": "04e6a2a9-675f-401f-8409-6b38c3faf9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.16\n",
      "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "Collecting langchain-openai==0.1.3\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
      "Collecting langchain-community==0.0.34\n",
      "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
      "Collecting openai==1.14.3\n",
      "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
      "Collecting tiktoken==0.6.0\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-win_amd64.whl (798 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (1.26.4)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (0.5.14)\n",
      "Collecting requests<3,>=2\n",
      "  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (2.0.45)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (1.10.24)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (4.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (0.1.147)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (3.13.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (6.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\venv-310\\lib\\site-packages (from langchain==0.1.16) (0.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\venv-310\\lib\\site-packages (from openai==1.14.3) (4.12.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\venv-310\\lib\\site-packages (from openai==1.14.3) (4.15.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\venv-310\\lib\\site-packages (from openai==1.14.3) (4.67.1)\n",
      "Requirement already satisfied: sniffio in c:\\venv-310\\lib\\site-packages (from openai==1.14.3) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\venv-310\\lib\\site-packages (from openai==1.14.3) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\venv-310\\lib\\site-packages (from openai==1.14.3) (0.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\venv-310\\lib\\site-packages (from tiktoken==0.6.0) (2025.11.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\venv-310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\venv-310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.22.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\venv-310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\venv-310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\venv-310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\venv-310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\venv-310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (25.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\venv-310\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.14.3) (3.11)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\venv-310\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.14.3) (1.3.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\venv-310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\venv-310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (3.26.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\venv-310\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.14.3) (1.0.9)\n",
      "Requirement already satisfied: certifi in c:\\venv-310\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.14.3) (2025.11.12)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\venv-310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.14.3) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\venv-310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.16) (3.0.0)\n",
      "Collecting packaging<24.0,>=23.2\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\venv-310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\venv-310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\venv-310\\lib\\site-packages (from requests<3,>=2->langchain==0.1.16) (2.6.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\venv-310\\lib\\site-packages (from requests<3,>=2->langchain==0.1.16) (3.4.4)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\venv-310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\venv-310\\lib\\site-packages (from tqdm>4->openai==1.14.3) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\venv-310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (1.1.0)\n",
      "Installing collected packages: requests, packaging, tenacity, langchain-core, tiktoken, openai, langchain-community, langchain-openai, langchain\n",
      "Successfully installed langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.53 langchain-openai-0.1.3 openai-1.14.3 packaging-23.2 requests-2.32.5 tenacity-8.5.0 tiktoken-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langgraph-checkpoint 3.0.1 requires langchain-core>=0.2.38, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-experimental 0.4.1 requires langchain-community<1.0.0,>=0.4.0, but you have langchain-community 0.0.34 which is incompatible.\n",
      "langchain-experimental 0.4.1 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.0.2 which is incompatible.\n",
      "langchain-classic 1.0.0 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.24 which is incompatible.\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\venv-310\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install  langchain==0.1.16   langchain-openai==0.1.3   langchain-community==0.0.34   openai==1.14.3   tiktoken==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "id": "qBr88t1d3kky",
    "outputId": "f576dac8-18be-49bf-fead-1fd9b486fbd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests==2.32.4Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Collecting tenacity==9.0.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting packaging==24.2\n",
      "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\venv-310\\lib\\site-packages (from requests==2.32.4) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\venv-310\\lib\\site-packages (from requests==2.32.4) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\venv-310\\lib\\site-packages (from requests==2.32.4) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\venv-310\\lib\\site-packages (from requests==2.32.4) (2025.11.12)\n",
      "Installing collected packages: tenacity, requests, packaging\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.5.0\n",
      "    Uninstalling tenacity-8.5.0:\n",
      "      Successfully uninstalled tenacity-8.5.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.5\n",
      "    Uninstalling requests-2.32.5:\n",
      "      Successfully uninstalled requests-2.32.5\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "Successfully installed packaging-24.2 requests-2.32.4 tenacity-9.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.1.16 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
      "langchain-core 0.1.53 requires packaging<24.0,>=23.2, but you have packaging 24.2 which is incompatible.\n",
      "langchain-core 0.1.53 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
      "langchain-community 0.0.34 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.0.2 which is incompatible.\n",
      "langchain-classic 1.0.0 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.24 which is incompatible.\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\venv-310\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install requests==2.32.4 tenacity==9.0.0 packaging==24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82qpRo7L4sAe",
    "outputId": "c5d61da0-cc91-4b54-9c8e-37a0630b917a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: openai 1.14.3Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Uninstalling openai-1.14.3:\n",
      "  Successfully uninstalled openai-1.14.3\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.12.0\n",
      "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: sniffio in c:\\venv-310\\lib\\site-packages (from openai==1.12.0) (1.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\venv-310\\lib\\site-packages (from openai==1.12.0) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\venv-310\\lib\\site-packages (from openai==1.12.0) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\venv-310\\lib\\site-packages (from openai==1.12.0) (4.15.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\venv-310\\lib\\site-packages (from openai==1.12.0) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\venv-310\\lib\\site-packages (from openai==1.12.0) (1.10.24)\n",
      "Requirement already satisfied: tqdm>4 in c:\\venv-310\\lib\\site-packages (from openai==1.12.0) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\venv-310\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.12.0) (3.11)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\venv-310\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.12.0) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\venv-310\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (1.0.9)\n",
      "Requirement already satisfied: certifi in c:\\venv-310\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (2025.11.12)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\venv-310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.12.0) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\venv-310\\lib\\site-packages (from tqdm>4->openai==1.12.0) (0.4.6)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-1.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\venv-310\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6VQ-KCF4wL-",
    "outputId": "62a7a0ab-910b-4f9e-bc16-9de2ef808d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: httpx 0.28.1\n",
      "Uninstalling httpx-0.28.1:\n",
      "  Successfully uninstalled httpx-0.28.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting httpx==0.27.2\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\venv-310\\lib\\site-packages (from httpx==0.27.2) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\venv-310\\lib\\site-packages (from httpx==0.27.2) (3.11)\n",
      "Requirement already satisfied: anyio in c:\\venv-310\\lib\\site-packages (from httpx==0.27.2) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\venv-310\\lib\\site-packages (from httpx==0.27.2) (2025.11.12)\n",
      "Requirement already satisfied: sniffio in c:\\venv-310\\lib\\site-packages (from httpx==0.27.2) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\venv-310\\lib\\site-packages (from httpcore==1.*->httpx==0.27.2) (0.16.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\venv-310\\lib\\site-packages (from anyio->httpx==0.27.2) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\venv-310\\lib\\site-packages (from anyio->httpx==0.27.2) (1.3.1)\n",
      "Installing collected packages: httpx\n",
      "Successfully installed httpx-0.27.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.1.16 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
      "langchain-core 0.1.53 requires packaging<24.0,>=23.2, but you have packaging 24.2 which is incompatible.\n",
      "langchain-core 0.1.53 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
      "langchain-community 0.0.34 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.0.2 which is incompatible.\n",
      "langchain-classic 1.0.0 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.24 which is incompatible.\n",
      "ddgs 9.9.3 requires httpx[brotli,http2,socks]>=0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\venv-310\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install httpx==0.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TUHDUK83vdj",
    "outputId": "5f90a53e-a895-4bd2-a27b-7d6f42ad3998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckduckgo-search in c:\\venv-310\\lib\\site-packages (8.1.1)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\venv-310\\lib\\site-packages (from duckduckgo-search) (8.3.1)\n",
      "Requirement already satisfied: lxml>=5.3.0 in c:\\venv-310\\lib\\site-packages (from duckduckgo-search) (6.0.2)\n",
      "Requirement already satisfied: primp>=0.15.0 in c:\\venv-310\\lib\\site-packages (from duckduckgo-search) (0.15.0)\n",
      "Requirement already satisfied: colorama in c:\\venv-310\\lib\\site-packages (from click>=8.1.8->duckduckgo-search) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\venv-310\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srwxofXh1YTN",
    "outputId": "7badcdc5-e42a-41fc-8377-0104dd26f915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies installed and environment loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the API key from the .env file\n",
    "dotenv_path = os.path.expanduser(\"~/dev.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "print(\"Dependencies installed and environment loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvTqAIZC1YTN"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ym53JrNC1YTN"
   },
   "source": [
    "## Part 1: The LangChain Agent Attempt (The Brittle Approach)\n",
    "\n",
    "Here, we'll try to force a standard `AgentExecutor` to perform the self-correction loop by cramming all the logic into a complex prompt. We are essentially *telling* the agent to follow our steps, but we cannot *enforce* it.\n",
    "\n",
    "**Hypothesis:** The agent will likely struggle to follow the cyclical instructions. It is heavily biased towards moving forward to a `Final Answer` and may ignore the command to loop back, especially if the initial results are weak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pz-WGkN51YTN"
   },
   "source": [
    "### 1.1: Define Tools and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JiwlEs3W1YTN"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Tool: The agent only has one tool, a web search.\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "tools = [search_tool]\n",
    "\n",
    "# LLM: Using a powerful model to give it the best chance.\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ghj0y1m1YTO"
   },
   "source": [
    "### 1.2: The Complex Prompt\n",
    "\n",
    "This is the core of the attempt. We modify a standard ReAct prompt to include a detailed, multi-step procedure. The agent's ability to follow these instructions is entirely dependent on the LLM's interpretation, making it unreliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdMBOtOF5biv",
    "outputId": "43bf88db-06ae-470a-ae18-4c33afca43a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchainhub==0.1.14 in c:\\venv-310\\lib\\site-packages (0.1.14)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\venv-310\\lib\\site-packages (from langchainhub==0.1.14) (2.32.4)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in c:\\venv-310\\lib\\site-packages (from langchainhub==0.1.14) (2.32.4.20250913)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\venv-310\\lib\\site-packages (from requests<3,>=2->langchainhub==0.1.14) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\venv-310\\lib\\site-packages (from requests<3,>=2->langchainhub==0.1.14) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\venv-310\\lib\\site-packages (from requests<3,>=2->langchainhub==0.1.14) (2025.11.12)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\venv-310\\lib\\site-packages (from requests<3,>=2->langchainhub==0.1.14) (3.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\venv-310\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install langchainhub==0.1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2knjpG2p1YTO"
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Pull a base ReAct prompt\n",
    "prompt_template = hub.pull(\"hwchase17/react\").copy()\n",
    "\n",
    "# Manually inject our complex, cyclical instructions\n",
    "prompt_template.template = \"\"\"\n",
    "You are an expert web researcher. Your goal is to provide a comprehensive answer. You MUST follow these steps precisely:\n",
    "\n",
    "Step 1: Initial Search. Use the search tool with a query based on the user's topic.\n",
    "Step 2: Critical Analysis. After getting the search results, you MUST pause and analyze them. Ask yourself: 'Are these results detailed enough to write a good answer?'\n",
    "Step 3: Decision and Self-Correction.\n",
    "- If the results ARE sufficient, proceed to Step 4.\n",
    "- If the results ARE NOT sufficient, you MUST formulate a new, more specific search query and go back to Step 1. This is a critical self-correction step.\n",
    "\n",
    "Step 4: Final Answer. Once you have sufficient information, synthesize it into a final, detailed answer.\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: your reasoning and plan for the next action (following the steps above)\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat multiple times)\n",
    "Thought: I now have enough information to answer the user's question.\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rl2NXo3x1YTO"
   },
   "source": [
    "### 1.3: Create and Run the Agent\n",
    "\n",
    "Now we assemble the agent and run it. Observe the `verbose` output carefully to see if it follows our instructions. The final output will be rendered as Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4QpZGTQb6KuK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore::DeprecationWarning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oicFyimE5x1g"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1e1hiykx1YTO",
    "outputId": "7c8e1609-58aa-4ea7-b594-c6793053015d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the question about the current President of India and provide a detailed biography including their political history, I will start by searching for the most recent information on the President of India.\n",
      "\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"current President of India 2023 biography political history\"\u001b[0m\u001b[36;1m\u001b[1;3mNo good DuckDuckGo Search Result was found\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv-310\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:47: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "c:\\venv-310\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:48: UserWarning: backend='api' is deprecated, using backend='auto'\n",
      "  ddgs_gen = ddgs.text(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mIt seems there was an issue with retrieving the search results. I will attempt the search again to gather the necessary information.\n",
      "\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"current President of India 2023 biography political history\"\u001b[0m\u001b[36;1m\u001b[1;3mNo good DuckDuckGo Search Result was found\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv-310\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:47: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "c:\\venv-310\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:48: UserWarning: backend='api' is deprecated, using backend='auto'\n",
      "  ddgs_gen = ddgs.text(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mIt seems there is an issue with retrieving search results at the moment. However, based on my knowledge as of October 2023, the current President of India is Droupadi Murmu. I will provide a detailed biography and political history based on the information available up to that point.\n",
      "\n",
      "Final Answer: \n",
      "\n",
      "**Droupadi Murmu: Biography and Political History**\n",
      "\n",
      "- **Early Life and Education**: Droupadi Murmu was born on June 20, 1958, in the Mayurbhanj district of Odisha, India. She belongs to the Santhal tribe, one of the largest tribal communities in India. Murmu completed her early education in Odisha and later graduated from Rama Devi Women's College in Bhubaneswar.\n",
      "\n",
      "- **Career in Education**: Before entering politics, Droupadi Murmu worked as a teacher. She served as an assistant professor at the Shri Aurobindo Integral Education and Research Institute, Rairangpur, and also worked as a junior assistant in the irrigation department of the Government of Odisha.\n",
      "\n",
      "- **Political Career**: Murmu's political career began with the Bharatiya Janata Party (BJP). She was elected as a councilor in the Rairangpur Nagar Panchayat in 1997. She served as the Vice-Chairperson of the Rairangpur Nagar Panchayat and later became the Chairperson.\n",
      "\n",
      "- **Legislative Roles**: Droupadi Murmu was elected as a Member of the Legislative Assembly (MLA) from Rairangpur in 2000 and served until 2009. During her tenure, she held various ministerial portfolios in the Odisha government, including Commerce and Transport, and Fisheries and Animal Resources Development.\n",
      "\n",
      "- **Governor of Jharkhand**: In 2015, Droupadi Murmu was appointed as the Governor of Jharkhand, making her the first woman to hold the position in the state. Her tenure as governor was marked by her focus on tribal rights and development.\n",
      "\n",
      "- **Presidency**: Droupadi Murmu was elected as the 15th President of India in July 2022. Her election was historic as she became the first tribal woman to hold the highest constitutional position in India. Her presidency is noted for her emphasis on social justice, education, and empowerment of marginalized communities.\n",
      "\n",
      "Droupadi Murmu's journey from a small tribal village to the presidency is a testament to her dedication and commitment to public service. Her leadership continues to inspire many, especially in the tribal and marginalized communities across India.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Agent's Final Answer (Formatted as Markdown) ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Droupadi Murmu: Biography and Political History**\n",
       "\n",
       "- **Early Life and Education**: Droupadi Murmu was born on June 20, 1958, in the Mayurbhanj district of Odisha, India. She belongs to the Santhal tribe, one of the largest tribal communities in India. Murmu completed her early education in Odisha and later graduated from Rama Devi Women's College in Bhubaneswar.\n",
       "\n",
       "- **Career in Education**: Before entering politics, Droupadi Murmu worked as a teacher. She served as an assistant professor at the Shri Aurobindo Integral Education and Research Institute, Rairangpur, and also worked as a junior assistant in the irrigation department of the Government of Odisha.\n",
       "\n",
       "- **Political Career**: Murmu's political career began with the Bharatiya Janata Party (BJP). She was elected as a councilor in the Rairangpur Nagar Panchayat in 1997. She served as the Vice-Chairperson of the Rairangpur Nagar Panchayat and later became the Chairperson.\n",
       "\n",
       "- **Legislative Roles**: Droupadi Murmu was elected as a Member of the Legislative Assembly (MLA) from Rairangpur in 2000 and served until 2009. During her tenure, she held various ministerial portfolios in the Odisha government, including Commerce and Transport, and Fisheries and Animal Resources Development.\n",
       "\n",
       "- **Governor of Jharkhand**: In 2015, Droupadi Murmu was appointed as the Governor of Jharkhand, making her the first woman to hold the position in the state. Her tenure as governor was marked by her focus on tribal rights and development.\n",
       "\n",
       "- **Presidency**: Droupadi Murmu was elected as the 15th President of India in July 2022. Her election was historic as she became the first tribal woman to hold the highest constitutional position in India. Her presidency is noted for her emphasis on social justice, education, and empowerment of marginalized communities.\n",
       "\n",
       "Droupadi Murmu's journey from a small tribal village to the presidency is a testament to her dedication and commitment to public service. Her leadership continues to inspire many, especially in the tribal and marginalized communities across India."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Create the Agent\n",
    "agent_v1 = create_react_agent(llm, tools, prompt_template)\n",
    "agent_executor_v1 = AgentExecutor(agent=agent_v1, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# Let's run it with a niche topic that likely requires re-searching\n",
    "topic = \"Who is the President of India? Also tell me the Biography of the president with the politcal history\"\n",
    "response_v1 = agent_executor_v1.invoke({\"input\": topic})\n",
    "\n",
    "# Render the final output as Markdown\n",
    "print(\"\\n--- Agent's Final Answer (Formatted as Markdown) ---\")\n",
    "display(Markdown(response_v1['output']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HM4FCra81YTO"
   },
   "source": [
    "### 1.4: Analysis of the LangChain Agent's Performance\n",
    "\n",
    "You will likely observe that the agent performs one search and then immediately proceeds to a `Final Answer`, even if the results are clearly insufficient. It fails to follow the instruction to loop back.\n",
    "\n",
    "**The core problem is the lack of control.** We are *suggesting* a workflow in the prompt, but the `AgentExecutor`'s fundamental design doesn't support enforcing this kind of cycle. This is a classic example of a workflow that is **not feasible** to implement reliably with this architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isIS3ucF1YTP"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOfGkkqm1YTP"
   },
   "source": [
    "## Part 2: The LangGraph Solution (The Robust Approach)\n",
    "\n",
    "Now, let's build the same agent using LangGraph. Instead of a complex prompt, we will define our workflow as an explicit graph of nodes and edges.\n",
    "\n",
    "**Hypothesis:** The LangGraph implementation will reliably execute the self-correction loop every time it's needed, because the flow is enforced by code, not suggested by a prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgCPiem81YTP"
   },
   "source": [
    "### 2.1: Define the State\n",
    "\n",
    "The `State` is a central concept in LangGraph. It's a single object (in this case, a dictionary) that gets passed between all the nodes in our graph. Each node can read from it and write to it, allowing us to track our progress through the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v85P2DSU1YTP",
    "outputId": "ccded28c-31f7-484c-ea62-34bbf15a1cb8"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"Represents the state of our research agent.\"\"\"\n",
    "    topic: str\n",
    "    messages: Annotated[List[BaseMessage], lambda x, y: x + y]\n",
    "    search_results: str | None\n",
    "    retries: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77NbyOxf1YTP"
   },
   "source": [
    "### 2.2: Define the Graph Nodes\n",
    "\n",
    "Nodes are the fundamental building blocks of a LangGraph workflow. Each node is a simple Python function that receives the current `state` and returns a dictionary containing the values to update in the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9Z5DlrL1YTP"
   },
   "source": [
    "#### Node 1: `initial_search_node`\n",
    "This node performs the first web search based on the initial topic and initializes our retry counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdV0M8Zv1YTP",
    "outputId": "344e3a7d-5bd4-452e-e443-5c0efaaa0b83"
   },
   "outputs": [],
   "source": [
    "def initial_search_node(state: AgentState):\n",
    "    print(\"---NODE: Initial Search---\")\n",
    "    search_results = search_tool.run(state['topic'])\n",
    "    return {\"search_results\": search_results, \"retries\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1GQGS8h1YTP"
   },
   "source": [
    "#### Node 2: `analyze_results_node` (Improved Logic)\n",
    "\n",
    "This node uses the LLM to act as a judge. **This is the improved version.** It now explicitly checks if the search tool failed. If so, it immediately decides the results are `insufficient`, making the agent more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPEuuMH41YTP",
    "outputId": "cc318433-52f7-4f60-f239-770cd6d37a4e"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def analyze_results_node(state: AgentState):\n",
    "    print(\"---NODE: Analyze Results---\")\n",
    "    search_results = state['search_results']\n",
    "\n",
    "    # Check for a failed search result explicitly.\n",
    "    if not search_results or \"No good DuckDuckGo Search Result was found\" in search_results:\n",
    "        print(\"Analysis Decision: Search failed, results are insufficient.\")\n",
    "        return {\"messages\": [SystemMessage(content=\"Analysis: insufficient\")]}\n",
    "\n",
    "    analysis_prompt = f\"\"\"You are an expert researcher. Analyze these search results for the topic '{state['topic']}' and determine if they are sufficient to write a comprehensive answer. Respond with only 'sufficient' or 'insufficient'.\\n\\nResults:\\n{state['search_results']}\"\"\"\n",
    "    response = llm.invoke(analysis_prompt)\n",
    "    decision = response.content.strip().lower()\n",
    "    print(f\"Analysis Decision: {decision}\")\n",
    "    return {\"messages\": [SystemMessage(content=f\"Analysis: {decision}\")]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOx4YNa91YTQ"
   },
   "source": [
    "#### Node 3: `rewrite_query_node`\n",
    "\n",
    "This node is only called if the analysis fails. It uses the LLM to generate a *better* search query and then executes the search again, updating the state with the new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OvmPrxo1YTQ",
    "outputId": "92581b0c-cac7-4019-fba4-61f73176bbc2"
   },
   "outputs": [],
   "source": [
    "def rewrite_query_node(state: AgentState):\n",
    "    print(\"---NODE: Rewrite Query---\")\n",
    "    retries = state['retries']\n",
    "    rewrite_prompt = f\"\"\"You are a search expert. Your search for '{state['topic']}' was insufficient. Rewrite it into a better, more specific search query.\"\"\"\n",
    "    new_query = llm.invoke(rewrite_prompt).content.strip()\n",
    "    print(f\"New Query: {new_query}\")\n",
    "    search_results = search_tool.run(new_query)\n",
    "    return {\"search_results\": search_results, \"retries\": retries + 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP0EK3o41YTQ"
   },
   "source": [
    "#### Node 4: `final_response_node`\n",
    "\n",
    "This is the final step, only reached when the results are deemed sufficient. It synthesizes all the gathered information into a comprehensive answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PmKh-5_1YTQ",
    "outputId": "9139baae-70c7-47c1-9915-ceca91bd771f"
   },
   "outputs": [],
   "source": [
    "def final_response_node(state: AgentState):\n",
    "    print(\"---NODE: Final Response---\")\n",
    "    response_prompt = f\"\"\"Based on the following search results, provide a detailed answer to the topic: '{state['topic']}'.\\n\\nResults:\\n{state['search_results']}\"\"\"\n",
    "    final_response = llm.invoke(response_prompt).content\n",
    "    return {\"messages\": [SystemMessage(content=final_response)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzfS1Mjo1YTQ"
   },
   "source": [
    "### 2.3: Define the Edges and Assemble the Graph\n",
    "\n",
    "Edges connect our nodes. A **conditional edge** is a special type of edge that uses a function to decide which node to go to next based on the current state. This is how we create our self-correction loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph==0.0.48\n",
      "  Downloading langgraph-0.0.48-py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in c:\\venv-310\\lib\\site-packages (from langgraph==0.0.48) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\venv-310\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (0.1.147)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\venv-310\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (1.33)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\venv-310\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\venv-310\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (6.0.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\venv-310\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\venv-310\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (1.10.24)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\venv-310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\venv-310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\venv-310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (3.11.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\venv-310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (2.32.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\venv-310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (0.27.2)\n",
      "Requirement already satisfied: certifi in c:\\venv-310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\venv-310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\venv-310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (3.11)\n",
      "Requirement already satisfied: anyio in c:\\venv-310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (4.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\venv-310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\venv-310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\venv-310\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\venv-310\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\venv-310\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (2.6.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\venv-310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.52->langgraph==0.0.48) (1.3.1)\n",
      "Installing collected packages: langgraph\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 0.0.32\n",
      "    Uninstalling langgraph-0.0.32:\n",
      "      Successfully uninstalled langgraph-0.0.32\n",
      "Successfully installed langgraph-0.0.48\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\venv-310\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "c:\\venv-310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedWriter name=3>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\venv-310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=4>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\venv-310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph==0.0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langgraph.graph\n",
    "import langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "id": "icX0iD6u1YTQ",
    "outputId": "3a3b5ae3-ad5d-44b7-a544-fecac24748f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# This function is our conditional edge.\n",
    "def should_continue_edge(state: AgentState):\n",
    "    # First, check for the max retries condition to prevent infinite loops\n",
    "    if state['retries'] > 2:\n",
    "        print(\"---DECISION: Max retries reached, ending.---\")\n",
    "        return \"end\"\n",
    "\n",
    "    # Check the analysis message in the state\n",
    "    last_message = state['messages'][-1].content\n",
    "    if \"insufficient\" in last_message:\n",
    "        print(\"---DECISION: Results are insufficient, rewriting query.---\")\n",
    "        return \"rewrite\"\n",
    "    else:\n",
    "        print(\"---DECISION: Results are sufficient, generating final response.---\")\n",
    "        return \"end\"\n",
    "\n",
    "# Assemble the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"initial_search\", initial_search_node)\n",
    "workflow.add_node(\"analyze_results\", analyze_results_node)\n",
    "workflow.add_node(\"rewrite_query\", rewrite_query_node)\n",
    "workflow.add_node(\"final_response\", final_response_node)\n",
    "\n",
    "workflow.set_entry_point(\"initial_search\")\n",
    "workflow.add_edge(\"initial_search\", \"analyze_results\")\n",
    "workflow.add_edge(\"rewrite_query\", \"analyze_results\") # The crucial loop!\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze_results\",\n",
    "    should_continue_edge,\n",
    "    {\"rewrite\": \"rewrite_query\", \"end\": \"final_response\"} # This dictionary maps the edge function's return value to a node name\n",
    ")\n",
    "workflow.add_edge(\"final_response\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"Graph compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpWxqCXt1YTQ"
   },
   "source": [
    "### 2.4: Visualize the Graph\n",
    "\n",
    "One of the best features of LangGraph is the ability to visualize your agent's structure. This makes it incredibly easy to understand and debug the flow.\n",
    "\n",
    "**Note:** This requires `graphviz` and its development libraries to be installed. The command below handles this for Debian-based systems like Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgK_1ruh1YTR",
    "outputId": "86b676f6-b2e5-4c5b-a6c5-d452f325c882"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sudo is disabled on this machine. To enable it, go to the \u001b]8;;ms-settings:developers\u001b\\Developer Settings page\u001b]8;;\u001b\\ in the Settings app\n",
      "c:\\venv-310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedWriter name=3>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\venv-310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=4>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\venv-310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\venv-310\\Scripts\\python.exe' 'c:\\venv-310\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\ADMINU~1\\AppData\\Local\\Temp\\tmp3r0964_v'\n",
      "       cwd: C:\\Users\\adminuser\\AppData\\Local\\Temp\\pip-install-u2nc41ug\\pygraphviz_4a72ea411d394edaa2583f1075e9f969\n",
      "  Complete output (88 lines):\n",
      "  C:\\Users\\adminuser\\AppData\\Local\\Temp\\pip-build-env-rifzy10q\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "  \n",
      "          By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "          or your builds will no longer be supported.\n",
      "  \n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    corresp(dist, value, root_dir)\n",
      "  C:\\Users\\adminuser\\AppData\\Local\\Temp\\pip-build-env-rifzy10q\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \n",
      "          License :: OSI Approved :: BSD License\n",
      "  \n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist._finalize_license_expression()\n",
      "  C:\\Users\\adminuser\\AppData\\Local\\Temp\\pip-build-env-rifzy10q\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \n",
      "          License :: OSI Approved :: BSD License\n",
      "  \n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  creating build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  running egg_info\n",
      "  writing pygraphviz.egg-info\\PKG-INFO\n",
      "  writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
      "  writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
      "  reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.swg'\n",
      "  warning: no files found matching '*.png' under directory 'doc'\n",
      "  warning: no files found matching '*.html' under directory 'doc'\n",
      "  warning: no files found matching '*.txt' under directory 'doc'\n",
      "  warning: no files found matching '*.css' under directory 'doc'\n",
      "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "  no previously-included directories found matching 'doc\\build'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  running build_ext\n",
      "  building 'pygraphviz._graphviz' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pygraphviz\n",
      "ERROR: Could not build wheels for pygraphviz which use PEP 517 and cannot be installed directly\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\venv-310\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "c:\\venv-310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedWriter name=3>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\venv-310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=4>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\venv-310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install system dependencies for visualization\n",
    "!sudo apt-get -qq install -y graphviz libgraphviz-dev\n",
    "!pip install -q pygraphviz\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    # Generate the visualization\n",
    "    graph_image = app.get_graph().draw_mermaid_png()\n",
    "    display(Image(graph_image))\n",
    "except Exception as e:\n",
    "    print(f\"Error generating visualization: {e}\")\n",
    "    print(\"Please ensure graphviz and its development libraries are installed correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06zIeuaY1YTR"
   },
   "source": [
    "### 2.5: Run the Graph and Observe the State\n",
    "\n",
    "Now we run our compiled graph. We will `stream` the events to inspect the **interim state** after each node runs. We also pass a `config` dictionary to set a higher recursion limit, preventing the `GraphRecursionError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "jXJEwEA81YTR",
    "outputId": "20638260-252c-4e01-fc88-5c11b5dd403b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running LangGraph App ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'__start__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m} \u001b[38;5;66;03m# Set a higher limit for safety\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Running LangGraph App ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m     12\u001b[0m     app\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m     13\u001b[0m         initial_input,\n\u001b[0;32m     14\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m     15\u001b[0m         stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     17\u001b[0m ):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# The 'step' object contains the output of the node that just ran\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     node_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(step\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     20\u001b[0m     node_output \u001b[38;5;241m=\u001b[39m step[node_name]\n",
      "File \u001b[1;32mc:\\venv-310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:667\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ChannelsManager(\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels, checkpoint\n\u001b[0;32m    663\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m channels, get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;66;03m# map inputs to channel updates\u001b[39;00m\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_writes \u001b[38;5;241m:=\u001b[39m deque(map_input(input_keys, \u001b[38;5;28minput\u001b[39m)):\n\u001b[0;32m    666\u001b[0m         \u001b[38;5;66;03m# discard any unfinished tasks from previous checkpoint\u001b[39;00m\n\u001b[1;32m--> 667\u001b[0m         checkpoint, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_next_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;66;03m# apply input writes\u001b[39;00m\n\u001b[0;32m    671\u001b[0m         _apply_writes(checkpoint, channels, input_writes)\n",
      "File \u001b[1;32mc:\\venv-310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1386\u001b[0m, in \u001b[0;36m_prepare_next_tasks\u001b[1;34m(checkpoint, processes, channels, for_execution)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;66;03m# Check if any processes should be run in next step\u001b[39;00m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;66;03m# If so, prepare the values to be passed to them\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, proc \u001b[38;5;129;01min\u001b[39;00m processes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m-> 1386\u001b[0m     seen \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mversions_seen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;66;03m# If any of the channels read by this process were updated\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m triggers \u001b[38;5;241m:=\u001b[39m [\n\u001b[0;32m   1389\u001b[0m         chan\n\u001b[0;32m   1390\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mtriggers\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1396\u001b[0m         \u001b[38;5;66;03m# If all trigger channels subscribed by this process are not empty\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;66;03m# then invoke the process with the values of all non-empty channels\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: '__start__'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_input = {\n",
    "    \"topic\": topic,\n",
    "    \"messages\": [HumanMessage(content=topic)]\n",
    "}\n",
    "\n",
    "config = {\"recursion_limit\": 50} # Set a higher limit for safety\n",
    "\n",
    "print(\"--- Running LangGraph App ---\")\n",
    "for i, step in enumerate(app.stream(initial_input, config=config)):\n",
    "    # The 'step' object contains the output of the node that just ran\n",
    "    node_name = list(step.keys())[0]\n",
    "    node_output = step[node_name]\n",
    "\n",
    "    print(f\"\\n--- STEP {i+1}: Executed Node '{node_name}' ---\")\n",
    "    print(\"Output of this node:\")\n",
    "    print(node_output)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Get the final state to print the answer\n",
    "final_state = app.invoke(initial_input, config=config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"          LANGGRAPH FINAL ANSWER\")\n",
    "print(\"=\"*50)\n",
    "display(Markdown(final_state['messages'][-1].content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBDqCSHl1YTR"
   },
   "source": [
    "### 2.6: Analysis of the LangGraph Performance\n",
    "\n",
    "As you can see from the output, the flow is explicit and reliable. The graph moves from node to node, the conditional edge correctly routes the flow back for a retry, and the state is updated predictably at each step. This is the power of defining your agent's logic as code rather than as a prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4p16xRP91YTR"
   },
   "source": [
    "## Conclusion: The Right Tool for the Job\n",
    "\n",
    "- **LangChain `AgentExecutor`:** An excellent tool for rapid prototyping and building agents where the workflow is relatively linear (Tool A -> Tool B -> Answer). It's the \"automatic transmission\" for getting started quickly.\n",
    "\n",
    "- **LangGraph:** The essential tool for building production-grade, reliable agents that require complex, stateful logic. It provides the \"manual transmission\" needed for fine-grained control over cycles, retries, and branching, which is impossible to achieve reliably with a standard agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsCASFqN8oY2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
